{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "Autograd: automatic differentiation\n",
    "===================================\n",
    "\n",
    "Central to all neural networks in PyTorch is the ``autograd`` package.\n",
    "Let’s first briefly visit this, and we will then go to training our\n",
    "first neural network.\n",
    "\n",
    "\n",
    "The ``autograd`` package provides automatic differentiation for all operations\n",
    "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
    "defined by how your code is run, and that every single iteration can be\n",
    "different.\n",
    "\n",
    "Let us see this in more simple terms with some examples.\n",
    "\n",
    "Variable\n",
    "--------\n",
    "\n",
    "``autograd.Variable`` is the central class of the package. It wraps a\n",
    "Tensor, and supports nearly all of operations defined on it. Once you\n",
    "finish your computation you can call ``.backward()`` and have all the\n",
    "gradients computed automatically.\n",
    "\n",
    "You can access the raw tensor through the ``.data`` attribute, while the\n",
    "gradient w.r.t. this variable is accumulated into ``.grad``.\n",
    "\n",
    ".. figure:: /_static/img/Variable.png\n",
    "   :alt: Variable\n",
    "\n",
    "   Variable\n",
    "\n",
    "There’s one more class which is very important for autograd\n",
    "implementation - a ``Function``.\n",
    "\n",
    "``Variable`` and ``Function`` are interconnected and build up an acyclic\n",
    "graph, that encodes a complete history of computation. Each variable has\n",
    "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
    "the ``Variable`` (except for Variables created by the user - their\n",
    "``grad_fn is None``).\n",
    "\n",
    "If you want to compute the derivatives, you can call ``.backward()`` on\n",
    "a ``Variable``. If ``Variable`` is a scalar (i.e. it holds a one element\n",
    "data), you don’t need to specify any arguments to ``backward()``,\n",
    "however if it has more elements, you need to specify a ``grad_output``\n",
    "argument that is a tensor of matching shape.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create a variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1  1\n",
      " 1  1\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Do an operation of variable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3  3\n",
      " 3  3\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-faedf5ea10b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/evelynz/anaconda3/lib/python3.5/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: grad_fn"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Do more operations on y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 27  27\n",
      " 27  27\n",
      "[torch.FloatTensor of size 2x2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Gradients\n",
    "---------\n",
    "let's backprop now\n",
    "``out.backward()`` is equivalent to doing ``out.backward(torch.Tensor([1.0]))``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "print gradients d(out)/dx\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
    "*Variable* “$o$”.\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can do many crazy things with autograd!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1208.4890\n",
      " -425.8905\n",
      "  110.1804\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  51.2000\n",
      " 512.0000\n",
      "   0.0512\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Read Later:**\n",
    "\n",
    "Documentation of ``Variable`` and ``Function`` is at\n",
    "http://pytorch.org/docs/autograd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Demo: Linear Regression\n",
    "-----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 60\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Toy Dataset \n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        nn.Module.__init__(self)\n",
    "        #super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/60], Loss: 9.9577\n",
      "Epoch [10/60], Loss: 4.1744\n",
      "Epoch [15/60], Loss: 1.8314\n",
      "Epoch [20/60], Loss: 0.8821\n",
      "Epoch [25/60], Loss: 0.4975\n",
      "Epoch [30/60], Loss: 0.3415\n",
      "Epoch [35/60], Loss: 0.2782\n",
      "Epoch [40/60], Loss: 0.2525\n",
      "Epoch [45/60], Loss: 0.2420\n",
      "Epoch [50/60], Loss: 0.2376\n",
      "Epoch [55/60], Loss: 0.2357\n",
      "Epoch [60/60], Loss: 0.2349\n"
     ]
    }
   ],
   "source": [
    "# Train the Model \n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    targets = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()  # zero gradients\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()  # compute new gradients\n",
    "    optimizer.step()  # SGD step\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3Xl4VOXd//H3dzASEwIIqAiCCSCU1taa4MKqKCJVQS3V\nNooLLlWp4oPgThUrqFgEaUVrW31EW+ki/jQoSlHqwlIsSREtcQXkERVEMYbVyNy/P04SMsOEZLac\nmcnndV255NxzZs53MGQ+ubdjzjlEREREwgX8LkBERERSk0KCiIiIRKSQICIiIhEpJIiIiEhECgki\nIiISkUKCiIiIRKSQICIiIhEpJIiIiEhECgkiIiISkUKCiIiIRBRXSDCzm8wsaGbTGzjvRDMrNbOd\nZvaemV0Uz3VFREQk+WIOCWZ2DPBz4M0GzssHngNeBo4CZgJ/NLNTYr22iIiIJF9MIcHMWgF/Ai4D\nvmrg9KuANc65G5xz7zrnZgFPAeNiubaIiIg0jVh7EmYB85xzixpx7vHAS2FtC4C+MV5bREREmsB+\n0T7BzH4G/BDo08indAQ2hrVtBFqbWUvn3K4I12gPnAqsA3ZGW6OIiEgzlg3kAwucc1/E80JRhQQz\nOwy4HxjinKuK58INOBX4cxJfX0REJNOdDzwZzwtE25NQBBwElJmZVbe1AAaZ2dVAS+ecC3vOZ8Ah\nYW2HAF9H6kWotg7gT3/6E717946yxNQzbtw4ZsyY4XcZCaP3k7oy6b2A3k8qy6T3Apn1fsrLyxk1\nahRUf5bGI9qQ8BLw/bC2x4By4J4IAQFgGfCjsLah1e312QnQu3dvCgsLoywx9bRp0yYj3kcNvZ/U\nlUnvBfR+UlkmvRfIvPdTLe7h+qhCgnNuG7C6bpuZbQO+cM6VVx/fBXR2ztXshfA74BdmNhV4FDgZ\n+AlwWpy1i4iISBIlYsfF8N6DQ4EutQ86tw44HRgCrMRb+nipcy58xYOIiIikkKhXN4Rzzp0Udjw6\nwjmv4c1nEBERkTShezc0geLiYr9LSCi9n9SVSe8F9H5SWSa9F8i895MoFnmuob/MrBAoLS0tzcSJ\nJCIiIlF5/3045BBo3brhc8vKyigqKgIocs6VxXPduIcbREQy0fr169m8ebPfZUgz9/nnMGyY9+cx\nY+DSS6FDhw507dq1Sa6vkCAiEmb9+vX07t2b7du3+12KSK0HH/S+cnJyKC8vb5KgoJAgIhJm8+bN\nbN++PWM2dJPMUbNR0ubNmxUSRET8lCkbuonESqsbREREJCKFBBEREYlIIUFEREQiUkgQERGRiBQS\nREQkZpMmTSIQiO2j5LHHHiMQCLB+/foEV7XHRx99RCAQ4PHHH4/p+U1RYypTSBARaYZWr17NqFGj\nOOyww8jOzqZz586MGjWK1atXN/zkOsws5pBgZphZTM9tKvHUOGfOHGbOnJngipqWQoKISDPz9NNP\nU1hYyD//+U8uueQSHnroIS677DJeeeUVCgsLefbZZxv9Wr/85S9j3nTqwgsvZMeOHU22e2BTe/LJ\nJ9M+JGifBBGRBHDOJe234kS+9po1a7jwwgvp0aMHr732Gu3atat97Nprr2XAgAFccMEFrFq1ivz8\n/HpfZ/v27eTk5BAIBNh///1jqsXMYn6uNA31JIiIxKiyspLbx45lSEEBZ3XpwpCCAm4fO5bKysqU\nfe17772XHTt28Pvf/z4kIAC0a9eOhx9+mK1bt3LvvffWttfMOygvL+e8886jXbt2DBw4MOSxunbu\n3MnYsWM56KCDaN26NWeddRaffPIJgUCAX/3qV7XnRRrvz8/PZ8SIESxZsoTjjjuOAw44gO7du/PE\nE0+EXGPLli1MmDCBH/zgB+Tl5dGmTRtOO+00Vq1aFfPfzerVqznppJPIycmhS5cuTJkyhWAwuNd5\nJSUlnHHGGXTu3Jns7Gx69OjB5MmTQ84dPHgwzz//fO2ciEAgQLdu3QCoqqritttuo0+fPrRt25ZW\nrVoxaNAgXnnllZhrTxb1JIiIxKCyspKRfftyXXk5k4JBDHDAglmzGLloEXOXLSMvLy/lXvu5554j\nPz+ffv36RXx84MCB5Ofn8/zzz9e21fRinHPOOfTs2ZO7776bmjsIRxqzv+iii3jqqae48MILOe64\n43j11Vc5/fTT9zov0nPNjPfff59zzjmHSy+9lIsvvphHH32U0aNH06dPn9ptstesWUNJSQnnnHMO\nBQUFbNy4kYcffpgTTzyR1atX07Fjx6j+XjZu3MiJJ55IMBjklltuIScnh9///vdkZ2fvde5jjz1G\nXl4e48ePp1WrVixatIjbbruNyspKpk6dCsDEiROpqKhgw4YN3H///TjnaNWqFQBff/01jz76KMXF\nxfz85z+nsrKSRx55hGHDhvHGG2/wgx/8IKrak8o5l3JfQCHgSktLnYhIUystLXUN/Qy67Zpr3AuB\ngHOw19f8QMDdPnZszNdP1mtXVFQ4M3Nnn332Ps8788wzXSAQcFu3bnXOOTdp0iRnZm7UqFF7nTtp\n0iQXCARqj8vKypyZufHjx4ecN3r0aBcIBNwdd9xR2/bYY4+5QCDgPvroo9q2/Px8FwgE3JIlS2rb\nPv/8c5edne2uv/762rZvvvlmr1o++ugjl52d7SZPnlzbtm7dOmdmbvbs2ft8z//zP//jAoGAW7Fi\nRW3b5s2bXdu2bfeqcefOnXs9/8orr3StWrUKqeuMM85wBQUFe50bDAZdVVVVSFtFRYXr2LGju+yy\ny/ZZZ2O+N2vOAQpdnJ/HGm4QEYnBknnzODVCVzTAsGCQJSUlKffaNUMVDfVC1Dz+9ddf17aZGVdc\ncUWD13jxxRcxM6666qqQ9muuuaa296Eh3/3ud0N6Ojp06ECvXr1Ys2ZNbVtWVlbtn4PBIF9++SU5\nOTn06tWLsrKyRl2nrhdeeIHjjz+eoqKi2rb27dtz/vnn73Vuy5Yta/+8detWvvjiCwYMGMD27dt5\n5513GryWmbHffl5HvnOOLVu28M0339CnT5+Yak8mhQQRkSg558itqqK+qYQG5FRVNfpDsaleu+bD\nv6F5DfWFiYKCggavUTMGH35ujx49Gl1npNUOBx54IFu2bKk9ds4xY8YMevbsScuWLenQoQMHH3ww\nb731FhUVFY2+Vt26jzjiiL3ae/XqtVfb6tWrOfvss2nbti2tW7fmoIMO4oILLgBo9LVnz57NUUcd\nRXZ2Nu3bt+fggw/m+eefj6n2ZNKcBBGRKJkZ27KycBDxw9wB27KyYlqRkMzXbt26NYceemiDk/tW\nrVpF586da8fQaxxwwAFRXzMWLVq0iNheNxhNmTKF2267jcsuu4zJkyfTrl07AoEA1157bcTJholS\nUVHBoEGDaNu2LZMnT6Zbt25kZ2dTWlrKTTfd1Khr/+lPf2L06NH8+Mc/5oYbbuDggw+mRYsW3HXX\nXSG9JalAIUFEJAb9hw9nwaxZDIvwofBiIMCAESNS8rXPOOMM/vjHP7J06dKIkxdff/111q1bt9dw\nQWMdfvjhBINB1q5dS/fu3Wvb33///ZhrjmTu3LmcdNJJ/P73vw9p/+qrrzjooIOifr3DDz88Yo3h\nwwevvPIKW7Zs4dlnn6V///617R9++OFez60vyM2dO5fu3bvz1FNPhbTfdtttUdedbBpuEBGJwYQp\nU5jeuzcvBALU/H7rgBcCAWb07s34yZNT8rWvv/56srOzueKKK/jyyy9DHvvyyy+58soryc3NZcKE\nCTG9/qmnnopzjgcffDCk/be//W1C95Fo0aLFXkMuf//739mwYUNMr3faaafxr3/9ixUrVtS2ff75\n5zz55JMRr1u3x+Cbb77Z6/0C5ObmRhw+iNRTsnz5cpYtWxZT7cmkngQRkRjk5eUxd9ky7ps4kekl\nJeRUVbE9K4v+I0Ywd/LkmJcoJvu1e/TowezZsxk1ahTf//73ufTSSykoKGDt2rU8+uijfPHFF/zl\nL39p1PyDSAoLCxk5ciT3338/mzdv5vjjj+fVV1+t/S09UUHhjDPO4M477+SSSy6hX79+vPXWW/z5\nz38O6b2Ixg033MATTzzBqaeeyrXXXktOTg5/+MMfyM/PDxme6devHwceeCAXXnghY8eOBbzhg0jv\nq6ioiL/97W+MHz+eY445hlatWnHGGWdwxhln8PTTT3PWWWdx+umns2bNGh5++GG+973vsXXr1tj+\nQpIl3uURyfhCSyBFxEeNWWYWLhgMJq2eZLz222+/7c4//3zXuXNn17JlS9epUyc3atQo99///nev\nc2uWOX7xxRcRH2vRokVI244dO9w111zjOnTo4PLy8txZZ53l3nvvPWdm7t577609L9ISyIKCAjdi\nxIi9rnPiiSe6k046qfZ4165d7vrrr3edO3d2ubm5btCgQW758uVu8ODBIeetW7fOBQKBBpdA1vyd\nDB482OXk5LguXbq4u+66yz366KN71bhs2TLXr18/l5ub6w477DB38803u4ULF7pAIOBeffXV2vO2\nbdvmRo0a5dq1a+cCgUDIcsh77rnHFRQUuAMOOMAVFRW5+fPnu4svvth169ZtnzU29RJIczHMkE02\nMysESktLSyksLPS7HBFpZsrKyigqKkI/gxJn5cqVFBYW8uc//5ni4mK/y0lbjfnerDkHKHLOxbWm\nUnMSREQkoXbu3LlX2/3330+LFi0YNGiQDxVJrDQnQUREEuree++ltLSUwYMHs99++zF//nwWLFjA\nFVdcQefOnf0uT6KgkCAiIgnVr18/XnrpJSZPnszWrVvp2rUrd9xxB7fccovfpUmUFBJERCShhgwZ\nwpAhQ/wuQxJAcxJEREQkIoUEERERiUghQURERCJSSBAREZGIogoJZnalmb1pZhXVX0vNbNg+zj/B\nzIJhX7vN7OD4SxcREZFkinZ1w/8BNwLv493F9GLgWTP7oXOuvJ7nOKAnUHsDc+fcpuhLFRERkaYU\nVUhwzj0f1jTRzK4CjgfqCwkAnzvnvo62OBEREfFPzHMSzCxgZj8DcoB93d/SgJVm9omZ/cPM9r6B\nuYiIpJTDDjuMn//8577W8OGHHxIIBPa6XXO4l19+mUAgwNKlS2vbRo0axRFHHJHsEjNe1CHBzI40\ns0pgF/AgcLZz7p16Tv8UuAIYCfwYb7jiFTP7YYz1iohIHGbPnk0gEIj4VXdHxEAgEHL74//+97/c\ncccdfPzxx3u95qxZs3jiiSeapP76hN+q2cwIBDQ3P16x7Lj4DnAU0Ab4CfC4mQ2KFBScc+8B79Vp\n+peZdQfGARfFcG0REYmTmXHnnXeSn58f0n7kkUfW/vnDDz+kRYsWtcdvv/02d9xxB6eccgqHHXZY\nyPMeeOABunTpwgUXXJDUuqPx2GOPkYp3OU6Ubdu2Ncl1og4JzrlvgTXVh/8xs2OBa4GrGvkSbwD9\nG3PiuHHjaNOmTUhbcXGxbjMqIhKnYcOG7fM22FlZWSHHzrm9fltPZXUDTia6/uKLWbhyJc899xxz\n5swJeayioiJh10lEX0wAaBnF+T/EG4Zo0IwZMygpKQn5UkAQEUm+unMSHnnkEc477zwABgwYQCAQ\noEWLFixdupQuXbrw7rvv8tJLL9UOWwwdOrT2db766ivGjh1L165dyc7OpmfPnkybNm2v623ZsoUL\nL7yQtm3b0q5dOy699FK+/jr2+e7hcxJq5jf85je/4eGHH6Z79+4ccMABHH/88fznP//Z6/nl5eWM\nHDmS9u3bk5OTw7HHHsv8+fNjrifRzl+7lvsmTqS4uHivz8kZM2Yk7DpR9SSY2V3AC8B6IA84HzgB\nGFr9+N1AJ+fcRdXH1wJrgf8C2cDlwGDglATVLyIiMaioqOCLL74IaWvfvn3tn+v2GgwePJhf/OIX\nPPjgg9x+++21H769evXigQceYMyYMbRv356bb74Z5xyHHnooANu3b2fgwIFs2rSJK6+8ksMOO4zF\nixdzww03sGnTJu69917A66UYPnw4y5cvZ8yYMfTq1Yu5c+cyevTomHsvzCzic2fPns327dsZM2YM\nzjmmTp3KyJEj+eCDD2rnMLz11lsMHDiQww8/nJtvvpmcnBz++te/MmLECJ555hnOOOOMmGpKpH7O\ncVNJCcycmdTrRDvccDAwGzgUqABWAUOdc4uqH+8IdKlz/v7AfUAnYHv1+Sc7516Lp2gREYmdc46T\nTz45pM3M2L17d8Tzu3XrxoABA3jwwQc55ZRT6NdvzyK1M888k5tuuomOHTvu1dN77733sn79et58\n883a+Q+XX345hxxyCDNnzuS6666jY8eOPP300yxdupT777+fsWPHAnDllVcyaNCgBL5rz4YNG/jg\ngw9o1aoVAN27d+cnP/kJL730Um0PyDXXXEOPHj1Yvnx57bDFmDFjOP7447nppptSIiQYkFNVlfRh\noGj3SbisgcdHhx3/Gvh1DHWJiKSN7dvhnfrWeCXId74DOTmJeS0z48EHH0z6EsGnnnqKE088kby8\nvJBeiyFDhjBt2jRef/11zjnnHObPn0/Lli1DllwGAgGuvvrqkGWNiXDeeefVBgSAgQMH4pxjzRpv\nqt3mzZt57bXXuOeee/jqq69qz3POceqppzJ58mQ+//xzDjrooITWFS0HbMvKSvo8kVhWN4iISB3v\nvANFRcm9Rmkp7GOeYdSOOeaYfU5cTIT333+f8vLyiB+oZsamTd7mu+vXr6dz585kZ2eHnNOrV6+E\n19SlS5eQ4wMPPBDw5kTU1Axw8803c9NNN9Vbt98hYakZA0aMSPp1FBJEROL0ne94H+LJvka6cc4x\nbNgwxo8fH/HxZISAhtS36qFmuWQwGATgxhtvZMiQIRHPLSgoSE5xUfhzQQELJ09O+nUUEkRE4pST\nk9jf8lPRvrq163usW7dubNu2jZNOOmmfr3344YezePFidu7cGdKb8E6yx3Ai6N69OwD7779/g3X7\n6dePPUZeXl7Sr6PtqEREpEG5ubk450LG6es+Fqn93HPP5fXXX2fRokV7PfbVV1/V/tZ+2mmnsWvX\nLh5++OHax3fv3s0DDzzQ5HszdOzYkQEDBvDQQw/VDofUtXnz5iatpz65ublNch31JIiINDOx7ER4\n9NFHEwgEuPvuu9m8eTMtW7bklFNOoV27dhQVFfHII49w11130b17dzp27MgJJ5zAjTfeyLx58/jR\nj37E6NGjOfroo9m6dSurVq3i6aefZsOGDbRu3Zqzzz6b448/ngkTJvDhhx/WLoHcvn17Ut9TfR56\n6CEGDRrEkUceyeWXX05BQQEbN25kyZIlbNq0iRUrViTsWqlOIUFEpJlpzG/n4fsMdOrUiYceeoip\nU6dy2WWXsXv3bl5//XX69evHpEmT+Pjjj5k6dSpbt27l5JNP5oQTTiA3N5fFixczZcoUnnrqKWbP\nnk2bNm3o2bMnkydPrl1lYGY8//zzXHvttTz++OO0aNGCs846i/vuu48+ffrE/J4i3c+hvvPqtn/v\ne99jxYoVTJo0if/93/9ly5YtHHzwwRx99NHcdtttjaonU1gq7m1tZoVAaWlpadJn34qIhCsrK6Oo\nqAj9DJJU05jvzZpzgCLnXFk819OcBBEREYlIIUFEREQiUkgQERGRiBQSREREJCKFBBEREYlIIUFE\nREQiUkgQERGRiBQSREREJCLtuCgiUo/y8nK/SxAJ0dTfkwoJIiJhOnToQE5ODqNGjfK7FJG95OTk\n0KFDhya5lkKCiCSVc67J7+QXr65du1JeXp4yd/zz0wcfwE9/GtpWWupPLeLp0KEDXbt2bZJrKSSI\nSMJVVlYy7dZbWTJvHrlVVWzLyqL/8OFMmDKFvLw8v8trlK5duzbZD+JUFZ7tNmyATp38qUX8oYmL\nIpJQlZWVjOzbl76zZrFw3Tqe3bCBhevW0XfWLEb27UtlZaXfJUoDpkwJDQg33gjOKSA0R+pJEJGE\nmnbrrVxXXs6wYLC2zYBhwSCuvJz7Jk5k0syZ/hUo9dq8GQ46KLQtGNy7R0GaD/UkiEhCLZk3j1Pr\nBIS6hgWDLCkpaeKKpDHy8kIDwooVXu+BAkLzppAgIgnjnCO3qor6PlcMyKmqwjnXlGXJPjzzjBcE\ntm71jgcP9sJBUZG/dUlq0HCDiCSMmbEtKwsHEYOCA7ZlZaXdaodM9M030LJlaNvOnXu3SfOmngQR\nSaj+w4ezIBD5R8uLgQADRoxo4ook3Omnh4aBv/7V6z1QQJBw6kkQkYSaMGUKIxctwlVPXjS8HoQX\nAwFm9O7N3MmT/S6x2XrzTfjhD/ccBwKwe7d/9UjqU0+CiCRUXl4ec5ctY/nVVzM0P58zO3dmaH4+\ny6++mrnLlqXNPgmZpGYCYt2A8NlnCgjSMPUkiEjC5eXlecscZ85Myx0XM8ltt8Gdd+45/uUv4Ve/\n8q8eSS8KCSKSVAoI/ti4ETp2DG3TngcSLQ03iIhkmKys0IDwn/9ozwOJjUKCiEiG+PvfvSDw7bfe\n8bBhXjioOxdBJBoabhARSXO7dkF29t5t++/vTz2SOdSTICKSxoYMCQ0Ic+d6vQcKCJII6kkQEUlD\nZWWhWyfn5MC2bf7VI5kpqp4EM7vSzN40s4rqr6VmNqyB55xoZqVmttPM3jOzi+IrWUSk+aqZgFg3\nIGzapIAgyRHtcMP/ATcChUARsAh41sx6RzrZzPKB54CXgaOAmcAfzeyUGOsVEWm2brnF2yWxxq9+\n5YWG8Ns7iyRKVMMNzrnnw5ommtlVwPFAeYSnXAWscc7dUH38rpkNAMYBC6MtVkSkOfr0U+jUKbRN\nN9KUphDzxEUzC5jZz4AcYFk9px0PvBTWtgDoG+t1RUSaE7PQgLBqlQKCNJ2oQ4KZHWlmlcAu4EHg\nbOfcO/Wc3hHYGNa2EWhtZrrfmIhIPZ58MnTzozPP9MLB97/vX03S/MSyuuEdvPkFbYCfAI+b2aB9\nBIWYjRs3jjZt2oS0FRcXU1xcnOhLiYikhB07vJUKdX3zjbeLoki4OXPmMGfOnJC2ioqKhL2+uTj7\nrcxsIfCBc+6qCI+9CpQ6566r03YxMMM5d+A+XrMQKC0tLaWwsDCu+kRE0sXAgbB48Z7jkhIYPty/\neiQ9lZWVUeQtfylyzpXF81qJ2CchANQ3dLAM+FFY21Dqn8MgItLsvPEGHHfcnuP27WHzZv/qEakR\nVUgws7uAF4D1QB5wPnAC3gc/ZnY30Mk5V7MXwu+AX5jZVOBR4GS8IYrTElK9iEgacy50SSN44aB9\ne3/qEQkX7cTFg4HZePMSXsLbK2Goc25R9eMdgS41Jzvn1gGnA0OAlXhLHy91zoWveBARyXh1h3cn\nTAgNCFOneqFBAUFSSbT7JFzWwOOjI7S9hhcmRESancrKSqbdeitL5s0jt6qKL6wLSz4OHXHVkkZJ\nVbp3g4hIklRWVjKyb1+uKy9nUjBIgNA08O9/b6NPn1yfqhNpmO4CKSKSJNNuvZXrysv5R/DXIQHh\nXP7K/EALnnviFh+rE2mYehJERJLk1Wdf4VfB3SFtVezHfuzGBWF6SQnMnOlTdSINU0+CiEgSmMGr\n61fVHv+Ga3AY++GFBgNyqqqId68akWRST4KIpDznHFZ3j+IU9te/ws9+Ftrm2Lt2B2zLykqb9yXN\nk3oSRCQlVVZWcvvYsQwpKOCsLl0YUlDA7WPHUllZ6XdpEQWDXu9B3YBw3SW38kKgRcTzXwwEGDBi\nRBNVJxIb9SSISMoJXxVgeL95L5g1i5GLFjF32TLy8vL8LrNWjx7w4Yd7js85B/72N6isvImRy5/F\nlZczrM77eDEQYEbv3sydPNmvkkUaRT0JIpJyalYF1HywgjeGPywYZFx5OfdNnOhnebXeesvrPagb\nEJzzAgJAXl4ec5ctY/nVVzM0P58zO3dmaH4+y6++OuWCjkgkcd/gKRl0gyeR5m1IQQEL162LMJLv\n/SY+ND+fhWvXNnVZIcKnEixdCn377vs56TS3QtJXIm/wpJ4EEUkpzjlyq6oiBgTwf1XAmDGhASEn\nx+s9aCggAAoIknY0J0FSgn7DkhpmxrasLBzU25Pgx6qALVugXbvQtqoq2E8/RSWDqSdBfJNus9el\n6fQfPpwF4bdHrObHqgCz0IDwu995vQcKCJLp9C0uvki32evStCZMmcLIRYt8XxXwpz/BBReEtqXg\nNC6RpFFPgvgiXWaviz/8XhWwe7fXe1A3IGzcqIAgzY9WN4gv0mH2uqSOppyzEn6ZCy6Axx9vkkuL\nJEQiVzdouEGaXDSz1zWZUaBpVgUsWgQnnxzaloK/Q4k0KQ03SJOrO3s9Eu1pL03NLDQg/OMfCggi\noJAgPkm12evSPB111N7DC87BKaf4U49IqlFIEF9MmDKF6b1780IgUNuj4IAXqmevj9ee9pJEn3zi\nhYNVe+7kTFWVeg9EwikkiC/8nr0uzZcZdO685/j227XngUh99M9CfJOXl8ekmTNh5kxNUpSkmzgR\npkwJbVPPgci+KSRISlBAkGSpqoL99w9t++QTOPRQf+oRSScabhCRjGUWGhAKC73eAwUEkcZRSBCR\njPPii5FXLZSW+lOPSLrScIOIZJTwcPDPf8KJJ/pSikjaU0gQaYYycaJojx7w4YehbZqYKBIfDTeI\nNBOZemvu9eu93oO6AeHbbxUQRBJBIUGkGai5NXffWbNYuG4dz27YwMJ16+g7axYj+/ZN26BgBocf\nvuf47ru9cNCihX81iWQShQSRZiDTbs19/fWRJybedJM/9YhkKoUEkWZgybx5nBoMRnxsWDDIkpKS\nJq4oNrt2eeFg2rQ9bZs2aWhBJFkUEkQyXDS35k5lZpCdvee4f38vHBx0kH81iWQ6hQSRDJfut+Yu\nKYk8tLB4cfKumeqBSaSpKCSINAPpemtuMzjzzD3HS5Ykb2ghU1d/iMQjqpBgZjeb2Rtm9rWZbTSz\n/2dmPRt4zglmFgz72m1mB8dXuog0Vrrdmrtz58i9B/36Jed6mbr6QyRe0fYkDAR+CxwHDAGygH+Y\n2QENPM8BRwAdq78Odc5tivLaIhKjdLk195o1Xjj45JM9bbt3J39iYqat/hBJFItn7M3MOgCbgEHO\nuYgjhGbDdP52AAAe1klEQVR2ArAIONA593UjX7cQKC0tLaWwsDDm+kQkslTccTG8nOnTYdy4prn2\nkIICFq5bF3FypwOG5uezcO3apilGJE5lZWUUFRUBFDnnyuJ5rXi3ZW6L92/oywbOM2ClmWUDbwOT\nnHNL47y2iMQolQLC0KGwcGFoW1POG4xm9Ucq/b2JNIWYQ4J5/1ruBxY751bv49RPgSuAFUBL4HLg\nFTM71jm3Mtbri0h6274dcnND2z77DA45pGnrqLv6o76ehFRe/SGSTPH0JDwIfBfov6+TnHPvAe/V\nafqXmXUHxgEX7eu548aNo02bNiFtxcXFFBcXx1SwiKSG8M/bjh3h00/9qQWqV3/MmsWwCBtOpfLq\nD5E5c+YwZ86ckLaKioqEvX5McxLM7AFgODDQObc+huffC/R3zkUMGJqTIJKZHnoIxowJbUuFLQlq\nVjeMqzN50eEFhBm9e6fU5E6Rhvg6J6E6IJwJnBBLQKj2Q7xhCBFpJsJ7D15+GU46yZ9awtWs/rhv\n4kSml5SQU1XF9qws+o8YwdzJkxUQpNmKKiSY2YNAMTAC2GZmNaOHFc65ndXn3AV0ds5dVH18LbAW\n+C+QjTcnYTBwSkLegYiktEhD+anQexAuLy+PSTNnwsyZmqQoUi3afRKuBFoDrwCf1Pk6t845hwJd\n6hzvD9wHrKp+3veBk51zr8RSsIikh5Ur9w4IwWBqBoRwCgginqh6EpxzDYYK59zosONfA7+Osi4R\nSWPhn7ETJ8Kdd/pTi4jELt59EkREag0Y4N1foa506DkQkcgUEkQkbpWV0Lp1aNvmzdC+vT/1iEhi\n6C6QIhIXs9CA0L2713uggCCS/hQSRCQm06dHvlPjBx/4U4+IJJ6GG0QkKs5BIOzXi9df9+YjiEhm\nUUgQkUZLlz0PRCQxNNwgIg3697/Td88DEYmdQoKI7JMZHHvsnuPJk71woP2GRDKfhhtEJKKjj/Z2\nTaxLPQcizYtCgoiE+OorOPDA0LYtW6BtW3/qERH/aLhBRGqZhQaEH/zA6z1QQBBpnhQSRIS77oq8\n58Gbb/pTj4ikBg03iDRjkfY8WL48dKKiiDRfCgkizZT2PBCRhmi4QaSZWbJEex6ISOMoJIg0I2ah\n2yffd5/2PBCR+mm4QaQZOPtseOaZ0Db1HIhIQxQSRDJYRcXeyxe3boXcXH/qEZH0ouEGkQxlFhoQ\nRo/2eg8UEESksRQSRDLM734Xec+DRx/1px4RSV8abhDJEJH2PHjnHejVy596RCT9KSSIZIDwnoPW\nrb35CCIi8dBwg0gaW7Ei8tCCAoKIJIJCgkiaMoNjjtlz/Pe/a1mjiCSWhhtE0syPfgQvvhjapnAg\nIsmgkCCSJr78Etq3D23bsQOys/2pR0Qyn4YbRJqIi+PXfbPQgDBmjNd7oIAgIsmkkCCSRJWVldw+\ndixDCgo4q0sXhhQUcPvYsVRWVjbq+TNnRp6YOGtWEooVEQmj4QaRJKmsrGRk375cV17OpGAQAxyw\nYNYsRi5axNxly8jLy4v43GAQWrQIbfvwQ+jWLelli4jUUk+CSJJMu/VWrisvZ1h1QAAwYFgwyLjy\ncu6bODHi88xCA0LHjl7vgQKCiDQ1hQSRJFkybx6nBoMRHxsWDLKkpCSkbenSyEMLn36arApFRPZN\nIUEkCZxz5FZVYfU8bkBOVVXtZEYz6N9/z+PPPqtljSLiP81JEEkCM2NbVhYOIgYFB2zLyuKEE4zX\nXw97TOFARFJEVD0JZnazmb1hZl+b2UYz+39m1rMRzzvRzErNbKeZvWdmF8Veskh66D98OAvC77hU\n7a92MC+vWxsSEHbuVEAQkdQS7XDDQOC3wHHAECAL+IeZHVDfE8wsH3gOeBk4CpgJ/NHMTomhXpG0\nMWHKFKb37s0LgQA1n/1ez4Kj2G2sPW/8eC8ctGzpS5kiIvWKarjBOXda3WMzuxjYBBQBi+t52lXA\nGufcDdXH75rZAGAcsDCqakXSSF5eHnOXLeO+iROZXlLChi8vp/zrW0LOUc+BiKSyeCcutsX75ejL\nfZxzPPBSWNsCoG+c1xZJeXl5efxy+kxeWrc2JCB89JECgoikvphDgpkZcD+w2Dm3eh+ndgQ2hrVt\nBFqbmTpYJaOZwX51+uu6d/fCQdeu/tUkItJY8fQkPAh8F/hZgmoRyRivvhp5z4MPPvCnHhGRWMS0\nBNLMHgBOAwY65xra6uUz4JCwtkOAr51zu/b1xHHjxtGmTZuQtuLiYoqLi6OsWKTphIeD+fO92zuL\niCTanDlzmDNnTkhbRUVFwl7for0zXXVAOBM4wTm3phHn3wP8yDl3VJ22J4G24RMh6zxeCJSWlpZS\nWFgYVX0ifikqgrKy0DbNOxCRplZWVkZRURFAkXOurKHz9yXafRIeBM4HzgO2mdkh1V/Zdc65y8xm\n13na74BuZjbVzHqZ2RjgJ8D0eAoXSRWffur1HtQNCN98o4AgIukv2jkJVwKtgVeAT+p8nVvnnEOB\nLjUHzrl1wOl4+yqsxFv6eKlzLnzFg0jaMYNOnfYc33KLFw6ysvyrSUQkUaLdJ6HBUOGcGx2h7TW8\nvRREMsJjj8HosO909RyISKbRvRtEorB7d+iSRoDPP4cOHfypR0QkmXQXSJFGOvjg0IAwerTXe6CA\nICKZSj0JIg1YsQKOOSa0TUMLItIcKCSI7EP4ngelpaBVuSLSXGi4QSSCiy4KDQidOnm9BwoIItKc\nqCdBpI7PP/fmHtT17bfQooU/9YiI+Ek9CSLVzEIDwuOPe70HCggi0lwpJEiz9/vfR74Z0wUX+FOP\niEiq0HCDNFvffrv3zohffAHt2vlTj4hIqlFPgjRLeXmhAeGqq7zeAwUEEZE91JMgzcqyZdCvX2ib\n9jwQEYlMIUGajfB5B2++CT/4gT+1iIikAw03SMb72c9CA0L37l7vgQKCiMi+qSdBMtZnn8Ghh4a2\n7d4NAUVjEZFG0Y9LyUhmoQHhL3/xeg8UEEREGk8/MiWjPPBA5D0PfvpTf+oREUlnGm5IA845LPyT\nT0JUVcH++4e2ffUVtGnjTz0iIplAPQkpqrKyktvHjmVIQQFndenCkIICbh87lsrKSr9LSzn77Rca\nEP7nf7zeAwWE9OO0HlUkpagnIQVVVlYysm9frisvZ1IwiAEOWDBrFiMXLWLusmXk5eX5XabvFi+G\ngQND2/QZk34qKyuZduutLJk3j9yqKrZlZdF/+HAmTJmi73MRn6knIQVNu/VWrisvZ1h1QAAwYFgw\nyLjycu6bONHP8lKCWWhAWL1aASEd1QTivrNmsXDdOp7dsIGF69bRd9YsRvbtq54zEZ8pJKSgJfPm\ncWowGPGxYcEgS0pKmrii1HHWWaETE4880gsHvXv7V5PEToFYJLUpJKQY5xy5VVXUN03RgJyqqmY3\ndrthgxcOnn12T1swCG+95V9NNZrb/4tEUiAWSW0KCSnGzNiWlUV9HzsO2JaV1axWO5jBYYftOZ47\n1+s98POvQBNL46dALJL6FBJSUP/hw1lQz64/LwYCDBgxookr8seMGZH3PPjxj/2pp4bG0RNDgVgk\n9SkkpKAJU6YwvXdvXggEan+AOuCFQIAZvXszfvJkP8tLul27vHBw3XV72r7+OnUmJmocPXEUiEVS\nm0JCCsrLy2PusmUsv/pqhubnc2bnzgzNz2f51Vdn/PJHM8jO3nN8441eOEilt6xx9MRp7oFYJNVp\nn4QUlZeXx6SZM2HmzGax4+KiRXDyyaFtqdJzUFc04+iZ/v8sEWoC8X0TJzK9pIScqiq2Z2XRf8QI\n5k6enNGBWCQdKCSkgXT8sInmQzL8tHffhZ49k1BUAtQdR4/07jSOHr3mFohF0omGGyRhop3xP3Ro\naEDo08frPUjVgFBD4+jJo4AgklrUkyAJEc1W0uvXw+GHhz4/GPR3SWM0JkyZwshFi3B1Ji86vIAw\no3dv5mocXUQyhHoSJCEaO+PfLDQglJT4v+dBtJrzxFIRaV4sFTcqMbNCoLS0tJTCwkK/y5FGGFJQ\nwMJ16+odpz+i7VQ+/OqG0PbU+9aLicbRRSSVlJWVUVRUBFDknCuL57U03CBx29eM/x1kk8MO+GpP\n29atkJvbZOUlnQKCiGSqqIcbzGygmZWY2QYzC5rZPmdpmdkJ1efV/dptZgfHXrakkvp2zjOcFxCq\n3Xab13uQSQFBRCSTxTInIRdYCYyBendUDeeAI4CO1V+HOuc2xXBtSVF1Z/wvYCgW9q1x+9hrueMO\nPyoTEZFYRT3c4Jx7EXgRwKLrZ/3cOfd1tNeT9DBhyhR+/PIifrT67ZD2R6wHf/luNuMnL/OpMhER\niVVTrW4wYKWZfWJm/zCzfk10XWki06bl8VKdgNB+/38xJL+A9decrhn/IiJpqikmLn4KXAGsAFoC\nlwOvmNmxzrmVTXB9SaKNG6Fjx9A277YGx2G21o+SREQkQZIeEpxz7wHv1Wn6l5l1B8YBFyX7+pI8\nWVnw7bd7jleuhKOOqjnSjH8RkXTn1xLIN4D+DZ00btw42rRpE9JWXFxMcXFxsuqSRvj73+Hcc/cc\nDxsGL7zgXz0iIs3VnDlzmDNnTkhbRUVFwl4/rs2UzCwInOWci+reuGb2D+Br59xP6nlcmymloF27\nQm/jXNO2//7+1CMiIntL5GZKseyTkGtmR5nZD6ubulUfd6l+/G4zm13n/GvNbISZdTez75nZ/cBg\n4IF4CpemdfLJoQFh7lxvzwMFBBGRzBXLcEMf4J94ex844L7q9tnAJXj7IHSpc/7+1ed0ArYDq4CT\nnXOvxVizNKHSUu/ujDVyc70dE0VEJPPFsk/Cq+yjB8I5Nzrs+NfAr6MvTfzkHITfDXnTJjjoIH/q\nERGRpqe7QMpebr45NCDceacXGhQQRESaF93gSWp9+il06hTalil3ahQRkeipJ0EAMAsNCG+9pYAg\nItLcKSQ0c08+6QWEGmee6YWDI4/0ryYREUkNGm5opnbsgJyc0LZvvvF2URQREQH1JDRLAweGBoSS\nEq/3QAFBRETqUk9CM/LGG3DccXuO27eHzZv9q0dERFKbQkIzEGnPg82bvZAgIiJSHw03+Cie+2Y0\n1oQJoQFh6lQvNCggiIhIQ9ST0MQqKyuZduutLJk3j9yqKrZlZdF/+HAmTJlCXl5ewq7z8cfQpUto\nm5Y0iohINBQSmlBlZSUj+/bluvJyJgWDGN7NLxbMmsXIRYuYu2xZQoJC3SWNAKtXQ+/ecb+siIg0\nMxpuaELTbr2V68rLGVYdEAAMGBYMMq68nPsmTozr9R9/PDQgnHuu13uggCAiIrFQT0ITWjJvHpOC\nwYiPDQsGmV5SAjNnRv2627d7d2esq6oK9tP/XRERiYN6EpqIc47cqiqsnscNyKmqinoy47HHhgaE\n+fO93gMFBBERiZc+SpqImbEtKwsHEYOCA7ZlZWHhEwrqsXQp9O+/57hTJ9iwIRGVioiIeNK2J6Ep\nlg8mWv/hw1kQvmFBtRcDAQaMGNHgazjnzTuoGxC+/FIBQUREEi+tQkJlZSW3jx3LkIICzurShSEF\nBdw+diyVlZV+l9YoE6ZMYXrv3rwQCFATcRzwQiDAjN69GT958j6ff801oXseTJ/uhYYDD0xaySIi\n0oylzXBDUy0fTKa8vDzmLlvGfRMnMr2khJyqKrZnZdF/xAjmTp5cb/3r18Phh4e2pWFHioiIpJm0\nCQl1lw/WqFk+6KqXD06KYWVAU8vLy/PqnDkT51yDcxDCH373XejZM4kFioiIVEub4YYl8+Zx6j6W\nDy4pKWniiuK3r4Awf35oQBg1yus9UEAQEZGmkhY9CdEsH2zs6oBUtWNH6G2cAb79Flq08KceERFp\nvtKiJ6Hu8sFIol0+mKouuyw0IPz7317vgQKCiIj4IS1CAiRm+WCqWrXKG1p45BHvuLjYCwd9+vhb\nl4iING9pMdwA3vLBkYsW4erc+8DhBYQZvXszt4Hlg6koGNy7l2Dr1r23WBYREfFD2vQk1CwfXH71\n1QzNz+fMzp0Zmp/P8quvTovlj+GmTw8NCE8/7fUeKCCIiEiqSJueBIh++WAq2rIF2rXbc9yzp7es\nUUREJNWkTU9CuHQMCOPHhwaEDRsUEEREJHWlVU9Cuvr3v727NdZ45hk480z/6hEREWkMhYQk2rUL\nvvtdWLPGOz7tNHjuub13URQREUlFaTvckOoeeACys/cEhDVr4PnnFRBERCR9qCchwdauhW7d9hw/\n8AD84hf+1SMiIhIrhYQECQbh9NPhxRe94x494O23oWVLf+sSERGJlYYbEuCZZ7w9D2oCwr//De+/\nr4AgIiLpTSEhDl9+6c0xOPts73j8eG2nLCIimSPqkGBmA82sxMw2mFnQzBq8aYKZnWhmpWa208ze\nM7OLYis3dVxzDbRvv+f4yy9h2jT/6hEREUm0WHoScoGVwBio98aMtcwsH3gOeBk4CpgJ/NHMTonh\n2r5bvtzrPXjgAe/4uee83oMDD/S3LhERkUSLeuKic+5F4EUAa9y2h1cBa5xzN1Qfv2tmA4BxwMJo\nr++XnTuhVy9Yv947HjHCm4ugJY0iIpKpmmJOwvHAS2FtC4C+TXDthLj/fjjggD0B4aOP4NlnFRBE\nRCSzNUVI6AhsDGvbCLQ2s5Se///hh14QGDfOO37oIW9ooWtXf+sSERFpCim9T8K4ceNo06ZNSFtx\ncTHFxcVJvW4wCEOHwssve8e9e8PKlbD//km9rIiISFTmzJnDnDlzQtoqKioS9vpNERI+Aw4JazsE\n+No5t2tfT5wxYwaFhYVJKyySp5+GkSP3HJeVwdFHN2kJIiIijRLpF+eysjKKiooS8vpNMdywDDg5\nrG1odXvK2LzZG1qoCQg33ugNLSggiIhIcxV1T4KZ5QI9gJppe93M7CjgS+fc/5nZ3UAn51zNXgi/\nA35hZlOBR/ECw0+A0+KuPkHGjPHmGwAEAt6eB2GjHCIiIs1OLD0JfYD/AKV4+yTcB5QBd1Q/3hHo\nUnOyc24dcDowBG9/hXHApc658BUPTW7pUq/3oCYgzJ8Pu3crIIiIiEBs+yS8yj7ChXNudIS214DE\nDJAkwI4d0L07fPqpd/zjH8NTT2lJo4iISF3N7t4N06ZBTs6egLB+Pcydq4AgIiISLqWXQCbS++9D\nz557jv/wB7jsMv/qERERSXUZHxKCQRg8GF57zTs+8khvWWNWlr91iYiIpLqMHm7429+gRYs9AWHl\nSnjrLQUEERGRxsjIkPD5594cg5/+1Du+5RZvz4OjjvK3LhERkXSSccMNl18Of/yj9+eWLWHTJmjd\n2t+aRERE0lHG9CQsXuz1HtQEhAULvNs7KyCIiIjEJu17ErZvh8MP97ZVBjj3XPjLX7SkUUREJF5p\n3ZMwdSrk5u4JCB9/DH/9qwKCiIhIIqRlT8K2bdCq1Z7jRx+F0Xvt8ygiIiLxSMuQsGqV99+jj4Y3\n3oD90vJdiIiIpLa0/Hjt29db0igiIiLJk9ZzEkRERCR5FBJEREQkIoUEERERiUghQURERCJSSBAR\nEZGIFBJEREQkIoUEERERiUghQURERCJSSBAREZGIFBJEREQkIoUEERERiUghQURERCJSSBAREZGI\nFBJEREQkIoUEERERiUghQURERCJSSBAREZGIFBJEREQkIoUEERERiUghQURERCJSSGgCc+bM8buE\nhNL7SV2Z9F5A7yeVZdJ7gcx7P4kSU0gws1+Y2Voz22Fm/zKzY/Zx7glmFgz72m1mB8dednrJtG8+\nvZ/UlUnvBfR+UlkmvRfIvPeTKFGHBDP7KXAfcDtwNPAmsMDMOuzjaQ44AuhY/XWoc25T9OWKiIhI\nU4mlJ2Ec8LBz7nHn3DvAlcB24JIGnve5c25TzVcM1xUREZEmFFVIMLMsoAh4uabNOeeAl4C++3oq\nsNLMPjGzf5hZv1iKFRERkaazX5TndwBaABvD2jcCvep5zqfAFcAKoCVwOfCKmR3rnFtZz3OyAcrL\ny6MsLzVVVFRQVlbmdxkJo/eTujLpvYDeTyrLpPcCmfV+6nx2Zsf7WuZ1BDTyZLNDgQ1AX+fc8jrt\nU4FBzrl99SbUfZ1XgI+ccxfV8/h5wJ8bXZiIiIiEO98592Q8LxBtT8JmYDdwSFj7IcBnUbzOG0D/\nfTy+ADgfWAfsjOJ1RUREmrtsIB/vszQuUYUE51yVmZUCJwMlAGZm1ce/ieKlfog3DFHfdb4A4ko/\nIiIizdjSRLxItD0JANOBx6rDwht4qx1ygMcAzOxuoFPNUIKZXQusBf6Ll24uBwYDp8RbvIiIiCRP\n1CHBOfe36j0RfoU3zLASONU593n1KR2BLnWesj/evgqd8JZKrgJOds69Fk/hIiIiklxRTVwUERGR\n5kP3bhAREZGIFBJEREQkopQJCWZ2s5m9YWZfm9lGM/t/ZtbT77piZWZXmtmbZlZR/bXUzIb5XVci\nmNlN1Tfqmu53LbEws9sj3HRstd91xcPMOpnZE2a22cy2V3/vFfpdVyyqbx4X/v8naGa/9bu2aJlZ\nwMzuNLM11f9fPjCziX7XFQ8za2Vm95vZuur3tNjM+vhdV2OY2UAzKzGzDdXfUyMinPOr6t2Bt5vZ\nQjPr4UetDWnovZjZ2Wa2oPpnQtDMfhDLdVImJAADgd8CxwFDgCzgH2Z2gK9Vxe7/gBuBQrytrBcB\nz5pZb1+rilP1HT9/jndjr3T2Nt7E25qbjg3wt5zYmVlbYAmwCzgV6A2MB7b4WVcc+rDn/0tHvJVQ\nDvibn0XF6Ca8HWfHAN8BbgBuMLOrfa0qPo/gLXs/HzgSWAi8VL3ZXqrLxZtsPwbveyqEmd0IXI33\nM+5YYBveDQz3b8oiG2mf76X68dfxvudinnyYshMXq1dQbMLbyXGx3/Ukgpl9AUxwzv2v37XEwsxa\nAaXAVcAvgf84567zt6romdntwJnOubT8TTucmd2DtwvqCX7Xkgxmdj9wmnMu7XoWzWwe8Jlz7vI6\nbU8B251zF/pXWWzMLBuoBIY7516s074CmO+cu8234qJkZkHgLOdcSZ22T4BfO+dmVB+3xrvtwEXO\nuZQNqZHeS53HDsfbhuCHzrlV0b52KvUkhGuLl36+9LuQeFV3Of4Mbz+JZX7XE4dZwDzn3CK/C0mA\nI6q76T40sz+ZWZeGn5KyhgMrzOxv1UN1ZWZ2md9FJUL1TeXOx/vtNR0tBU42syMAzOwovN1m5/ta\nVez2w7t/z66w9h2kcW8cgJkV4PVc1b2B4dfAcvZ9A8OMFstmSklXvYvj/cBi51zajhWb2ZF4oaAm\nfZ9dfXvttFMdcn6I1xWc7v4FXAy8CxwKTAJeM7MjnXPbfKwrVt3wenfuA6bgdZP+xsx2Oeee8LWy\n+J0NtAFm+11IjO4BWgPvmNluvF/MbnXO/cXfsmLjnNtqZsuAX5rZO3i/ZZ+H9yH6vq/Fxa8j3i+m\nkW5g2LHpy0kNKRkSgAeB77Lv+zukg3eAo/B+yP0EeNzMBqVbUDCzw/BC2xDnXJXf9cTLOVd3P/O3\nzewN4CPgXCAdh4ICwBvOuV9WH79ZHVCvBNI9JFwCvOCci+beMKnkp3gfoj8DVuMF7Zlm9kkaB7hR\nwKN4N/v7FijD20a/yM+iJDlSbrjBzB4ATgNOdM7Ve3+HdOCc+9Y5t8Y59x/n3K14k/2u9buuGBQB\nBwFlZlZlZlXACcC1ZvZNdc9P2nLOVQDvASk5i7kRPgXC76teDnT1oZaEMbOueJOY/+B3LXG4F7jH\nOfd359x/nXN/BmYAN/tcV8ycc2udc4PxJsZ1cc4dj7ez7hp/K4vbZ4AR/w0MM0pKhYTqgHAmMNg5\nt97vepIgALT0u4gYvAR8H++3oKOqv1YAfwKOcqk6+7WRqidk9mAfNx1LcUuAXmFtvfB6R9LZJXhd\nvek6fg/ePKTdYW1BUuxnbyycczuccxvN7EC8VTXP+F1TPJxza/HCwMk1bdUTF48jQTdL8lHMP6NT\nZrjBzB4EioERwDYzq0lzFc65tLtdtJndBbwArAfy8CZfnQAM9bOuWFSP04fMDTGzbcAXzrnw32BT\nnpn9GpiH9yHaGbgDqALm+FlXHGYAS8zsZrxlgscBl+HdTC0tVfdOXQw85pwL+lxOPOYBE83sY7yb\n3BXi3RTvj75WFQczG4r3G/e7wBF4vSWrqb7JXyozs1y8Xwhqej+7VU8m/dI59394w6oTzewDYB1w\nJ/Ax8KwP5e5TQ++lOrx1xfsZZ8B3qv9dfeacC593UT/nXEp84aXr3RG+LvS7thjfzx/xut924KXT\nfwAn+V1XAt/fImC633XEWPscvH/4O/BC3JNAgd91xfmeTsO7edp2vA+jS/yuKc73c0r1v/8eftcS\n5/vIxbtz7lq8Nffv44XS/fyuLY73dA7wQfW/nw3ATCDP77oaWfsJ9XzWPFrnnEnAJ9X/lhak6vdg\nQ+8FuKiex2+L5jopu0+CiIiI+Cvtx8VEREQkORQSREREJCKFBBEREYlIIUFEREQiUkgQERGRiBQS\nREREJCKFBBEREYlIIUFEREQiUkgQERGRiBQSREREJCKFBBEREYno/wMZt7bYriPvSgAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d8b6fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the graph\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save the Model (binary)\n",
    "torch.save(model.state_dict(), 'model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Demo: Logistic Regression for Image Classification for MNIST\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters \n",
    "input_size = 784 # 28 x 28\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded\n"
     ]
    }
   ],
   "source": [
    "# MNIST Dataset (Images and Labels)\n",
    "# This will take a bit of time to download...\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Examine your dataset!\n",
    "for images, labels in test_loader:\n",
    "    break\n",
    "imshow(vutils.make_grid(images, nrow=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create your own Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "# TODO: create a SGD optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Define the training procedure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5], Step: [100/600], Loss: 2.2738\n",
      "Epoch: [1/5], Step: [200/600], Loss: 2.1211\n",
      "Epoch: [1/5], Step: [300/600], Loss: 2.0231\n",
      "Epoch: [1/5], Step: [400/600], Loss: 1.9717\n",
      "Epoch: [1/5], Step: [500/600], Loss: 1.8848\n",
      "Epoch: [1/5], Step: [600/600], Loss: 1.7751\n",
      "Epoch: [2/5], Step: [100/600], Loss: 1.7272\n",
      "Epoch: [2/5], Step: [200/600], Loss: 1.6720\n",
      "Epoch: [2/5], Step: [300/600], Loss: 1.6235\n",
      "Epoch: [2/5], Step: [400/600], Loss: 1.5236\n",
      "Epoch: [2/5], Step: [500/600], Loss: 1.5421\n",
      "Epoch: [2/5], Step: [600/600], Loss: 1.4891\n",
      "Epoch: [3/5], Step: [100/600], Loss: 1.4601\n",
      "Epoch: [3/5], Step: [200/600], Loss: 1.4084\n",
      "Epoch: [3/5], Step: [300/600], Loss: 1.4101\n",
      "Epoch: [3/5], Step: [400/600], Loss: 1.2909\n",
      "Epoch: [3/5], Step: [500/600], Loss: 1.2714\n",
      "Epoch: [3/5], Step: [600/600], Loss: 1.3330\n",
      "Epoch: [4/5], Step: [100/600], Loss: 1.2651\n",
      "Epoch: [4/5], Step: [200/600], Loss: 1.1251\n",
      "Epoch: [4/5], Step: [300/600], Loss: 1.2280\n",
      "Epoch: [4/5], Step: [400/600], Loss: 1.2254\n",
      "Epoch: [4/5], Step: [500/600], Loss: 1.1993\n",
      "Epoch: [4/5], Step: [600/600], Loss: 1.1642\n",
      "Epoch: [5/5], Step: [100/600], Loss: 1.1872\n",
      "Epoch: [5/5], Step: [200/600], Loss: 1.0798\n",
      "Epoch: [5/5], Step: [300/600], Loss: 1.0975\n",
      "Epoch: [5/5], Step: [400/600], Loss: 1.0987\n",
      "Epoch: [5/5], Step: [500/600], Loss: 1.0174\n",
      "Epoch: [5/5], Step: [600/600], Loss: 1.0201\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        # TODO: Fill in this section!\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 82 %\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "torch.save(model.state_dict(), 'mnist_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
